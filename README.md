# Transcontinental_Whispers
Concept for a transcontinental, collaborative audiovisual Performance

An MXZEHN Artwork hosted by AEEJA & The NODE Institute
__________________________________________
Introduction

Dear TouchDesigneurs,
there is a concept, I have been carrying around for almost ten years and I feel like now is the time to realise it. It is the idea of a collaborative, global, live, audio-visual, improvised performance and I would like to invite you to join the experience for the first time next month. 

The first edition of this performance dubbed “Global Whispers” will be hosted on December 6th 2020 by the AEEJA Video Room - the space for people to share creative efforts in realtime. AEJAA was conceived out of the need to collaborate remotely - without compromising audio or visual quality and features a multi-faceted program of audiovisual performances. With support by The NODE Institute - the European hub for creative visual programming,
I hope to put together a group of experienced audiovisual performers that can help me to make that dream true.
__________________________________________
The Idea

The concept is roughly based and best explained by the well known conversation game “Chinese Whispers”, in which one of a group of participants whispers a word in their neighbours ear, who then whispers the word - or what they think they understand - into the next person's ear.
The entertainment arises from the distortions the word experiences through the participants as “human factor” filters. We propose a similar approach to a collaborative, improvised audiovisual performance in which the participants are spread over all continents.

In our “game”, we have 6 participants, who can send and receive a video and audio stream over the internet. Each “participant” should be able to receive, remix and stream out such a Full HD stream. It can be one audiovisual artist or a team of two or more, that perform the audio and the video - let’s call this unit further “Station”. Either way, all artists in one Station should be in the same physical space, so their signals are in the same time and leave synced inside one av stream without further effort.

Let's start with the first Station: The VJ and the musician, both generate a signal (Image & Sound) and stream it to the next Station - if you imagine them standing in a circle to their right hand neighbours. Those open the incoming streams in their creative real time application of choice, add their remix and stream the signal on to the next station - and so on. Each station sees and hears only their nearest neighbour.

The magic begins to happen, when the last Station's output is used as the input for the first Station and we enter a global feedback loop - which means, now every Station is connected with every other Station and they all swing with each other.

__________________________________________
Obviously, there are a few rules to follow to make the game fun for everybody:

* Each Station can only remix the incoming signal, not completely overwrite. More than 50% of the “original” incoming signal needs to be preserved in the outgoing signal.
  (How that percentage is measured is up to personal artistic considerations : )

* For clarity, Stations shall not break the circle (make cross connections).
  (The signal flow has to stay in consistent order)

While traditionally, you would try to have all stations in sync to have control over the music, we will profit greatly from the biggest flaw of “real time” streaming: the delays. They are the salt in the constantly flowing media stream, that we now send around the globe. Like a Loop Station, this feedback will not forget things, they can only “degrade” over time and after a while they will come back. We will work with a delay of 20 - 30 seconds on each Station, adding up to roughly 2 minutes, that a change you made reappears on your input.

In a future, funded version, we envision an arena-like situation in which translucent screens are arranged in a circle and the audience surrounds the circle of screens and can watch the signal “travelling” from screen to screen, from location to location - as such stages could happen at several places at the same time and performers could be locally present or only via their streams.

Ultimately the artwork as a whole will only be perceivable in a real world scenario, 
however in this proposal, we decided to go another route: 

The performance should last about 1 hour and each Station will record their local audio-visual signal with a time-stamp - locally.
From these recordings, it will be possible to reconstruct the passage of the signal and make it perceivable as an animation, an interactive website, VR / AR experience or - and we would prefer it that way - in an exhibition, where the screens and speakers are arranged in a circle as would have the screens in the real world performance arrangement. 

__________________________________________
Technology

By using the TouchDesigner multimedia development environment, we can make sure every station is working on the same infrastructure and can focus on the remote performance rather than troubleshooting for hours. As every station is only receiving one audiovisual stream and sending one audiovisual stream, the bandwidth available to each station doesn’t have to be gigantic. By collecting local recordings we avoid the issue of receiving all the stations streams on one server but can document the complete performance.
